{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import seaborn\n",
    "import re\n",
    "import statsmodels.formula.api\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Configure how graphs will show up in this notebook\n",
    "%matplotlib inline\n",
    "seaborn.set_context('notebook', rc={'figure.figsize': (10, 6)}, font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(filename):\n",
    "    \"\"\"\n",
    "    Load a DataFrame from the generalized text format used by word2vec, GloVe,\n",
    "    fastText, and ConceptNet Numberbatch. The main point where they differ is\n",
    "    whether there is an initial line with the dimensions of the matrix.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    rows = []\n",
    "    with open(filename, encoding='utf-8') as infile:\n",
    "        for i, line in enumerate(infile):\n",
    "            items = line.rstrip().split(' ')\n",
    "            if len(items) == 2:\n",
    "                # This is a header row giving the shape of the matrix\n",
    "                continue\n",
    "            labels.append(items[0])\n",
    "            values = np.array([float(x) for x in items[1:]], 'f')\n",
    "            rows.append(values)\n",
    "    \n",
    "    arr = np.vstack(rows)\n",
    "    return pd.DataFrame(arr, index=labels, dtype='f')\n",
    "\n",
    "embeddings = load_embeddings('../fyp-data/word_embeddings/glove.42B.300d.txt')\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lexicon(filename):\n",
    "    \"\"\"\n",
    "    Load a file from Bing Liu's sentiment lexicon\n",
    "    (https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html), containing\n",
    "    English words in Latin-1 encoding.\n",
    "    \n",
    "    One file contains a list of positive words, and the other contains\n",
    "    a list of negative words. The files contain comment lines starting\n",
    "    with ';' and blank lines, which should be skipped.\n",
    "    \"\"\"\n",
    "    lexicon = []\n",
    "    with open(filename, encoding='latin-1') as infile:\n",
    "        for line in infile:\n",
    "            line = line.rstrip()\n",
    "            if line and not line.startswith(';'):\n",
    "                lexicon.append(line)\n",
    "    return lexicon\n",
    "\n",
    "pos_words = load_lexicon('../fyp-data/sentiment_lexicons/positive-words.txt')\n",
    "neg_words = load_lexicon('../fyp-data/sentiment_lexicons/negative-words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_vectors = embeddings.reindex(pos_words).dropna()\n",
    "neg_vectors = embeddings.reindex(neg_words).dropna()\n",
    "\n",
    "vectors = pd.concat([pos_vectors, neg_vectors])\n",
    "targets = np.array([1 for entry in pos_vectors.index] + [-1 for entry in neg_vectors.index])\n",
    "labels = list(pos_vectors.index) + list(neg_vectors.index)\n",
    "\n",
    "train_vectors, test_vectors, train_targets, test_targets, train_labels, test_labels = \\\n",
    "    train_test_split(vectors, targets, labels, test_size=0.1, random_state=0)\n",
    "\n",
    "model = SGDClassifier(loss='log', random_state=0, max_iter=100)\n",
    "model.fit(train_vectors, train_targets)\n",
    "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
    "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
    "       learning_rate='optimal', loss='log', max_iter=100, n_jobs=1,\n",
    "       penalty='l2', power_t=0.5, random_state=0, shuffle=True, verbose=0,\n",
    "       warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(model.predict(test_vectors), test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vecs_to_sentiment(vecs):\n",
    "    # predict_log_proba gives the log probability for each class\n",
    "    predictions = model.predict_log_proba(vecs)\n",
    "\n",
    "    # To see an overall positive vs. negative classification in one number,\n",
    "    # we take the log probability of positive sentiment minus the log\n",
    "    # probability of negative sentiment.\n",
    "    return predictions[:, 1] - predictions[:, 0]\n",
    "\n",
    "\n",
    "def words_to_sentiment(words):\n",
    "    vecs = embeddings.loc[words].dropna()\n",
    "    log_odds = vecs_to_sentiment(vecs)\n",
    "    return pd.DataFrame({'sentiment': log_odds}, index=vecs.index)\n",
    "\n",
    "\n",
    "# Show 20 examples from the test set\n",
    "words_to_sentiment(test_labels).iloc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "TOKEN_RE = re.compile(r\"\\w.*?\\b\")\n",
    "# The regex above finds tokens that start with a word-like character (\\w), and continues\n",
    "# matching characters (.+?) until the next word break (\\b). It's a relatively simple\n",
    "# expression that manages to extract something very much like words from text.\n",
    "\n",
    "\n",
    "def text_to_sentiment(text):\n",
    "    tokens = [token.casefold() for token in TOKEN_RE.findall(text)]\n",
    "    sentiments = words_to_sentiment(tokens)\n",
    "    return sentiments['sentiment'].mean()\n",
    "\n",
    "def text_to_rating(text):\n",
    "    return (text_to_sentiment(text) + 10) / 20 * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_sentiment(u\"It's a truly great phone, at a grossly inflated price. You \"\n",
    "                 u\"would be foolish if you didn't think a large amount of \"\n",
    "                 u\"what you are paying for is branding. Yes - you do get a lot \"\n",
    "                 u\"of tech with this. And I find that even though some other phones \"\n",
    "                 u\"are technically superior the iPhone seems to run better HOWEVER \"\n",
    "                 u\"this is nearly one thousand pounds. That is a big investment - \"\n",
    "                 u\"more than a laptop. If you can afford it, it won't disappoint but \"\n",
    "                 u\"it's defiantly not that much better than the older versions which \"\n",
    "                 u\"are 2/3 of the price.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_sentiment(\"Really disappointed with this screen protector. Followed instructions and fitted to phone perfectly. Once secured you are unable to pull down the screen (to show notifications / wifi / sound shortcuts) due to protector being slightly too short. (any higher then protector would have covered camera). I tried to remove protector to lift it slightly and it shattered in my hand.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_rating(\"I had gone to a local shop to get a tempered screen for my Samsung s8 and each time the screen had come lose so my temper (pardon the pun) was being tested. After going through reviews (Amazon just put up the verified purchased ones) I decided to opt for the Amazon choice one and I am now a very happy individual the screen arrived promptly and I was able following the online video to install it right first time no bubbles, no dust. Just make sure you click the edges down a few times to ensure that it clicks into place and please use the template surround that really helps too. Quality is excellent and the no problem with touch response. All in all the best tempered screen protector that I have bought.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_sentiment(\"I had gone to a local shop to get a tempered screen for my Samsung s8 and each time the screen had come lose so my temper (pardon the pun) was being tested. After going through reviews (Amazon just put up the verified purchased ones) I decided to opt for the Amazon choice one and I am now a very happy individual the screen arrived promptly and I was able following the online video to install it right first time no bubbles, no dust. Just make sure you click the edges down a few times to ensure that it clicks into place and please use the template surround that really helps too. Quality is excellent and the no problem with touch response. All in all the best tempered screen protector that I have bought.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_sentiment(\"This phone is the worst I have ever had!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "example_review = (u\"It's a truly great phone, at a grossly inflated price. You \"\n",
    "                 u\"would be foolish if you didn't think a large amount of \"\n",
    "                 u\"what you are paying for is branding. Yes - you do get a lot \"\n",
    "                 u\"of tech with this. And I find that even though some other phones \"\n",
    "                 u\"are technically superior the iPhone seems to run better HOWEVER \"\n",
    "                 u\"this is nearly one thousand pounds. That is a big investment - \"\n",
    "                 u\"more than a laptop. If you can afford it, it won't disappoint but \"\n",
    "                 u\"it's defiantly not that much better than the older versions which \"\n",
    "                 u\"are 2/3 of the price.\")\n",
    "\n",
    "reviews = []\n",
    "\n",
    "tokens = nlp(example_review)\n",
    "\n",
    "for token in tokens:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
