{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import numpy as np #Linear algebra.\n",
    "import pandas as pd #Data processing.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, SGDClassifier\n",
    "from sklearn import neighbors, svm #K-nearest neighbours and Support-vector machine\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_reviews = pd.read_csv(\"D:/fyp-data/amazon_reviews/amazon_reviews_us_Books_v1_00.tsv\",\n",
    "                      usecols=['review_body', 'star_rating'], sep='\\t', skiprows=lambda i: i>0 and random.random() > 0.0002)\n",
    "\n",
    "music_reviews = pd.read_csv(\"D:/fyp-data/amazon_reviews/amazon_reviews_us_Music_v1_00.tsv\",\n",
    "                      usecols=['review_body', 'star_rating'], sep='\\t', skiprows=lambda i: i>0 and random.random() > 0.0004)\n",
    "\n",
    "electronics_reviews = pd.read_csv(\"D:/fyp-data/amazon_reviews/amazon_reviews_us_Electronics_v1_00.tsv\",\n",
    "                      usecols=['review_body', 'star_rating'], sep='\\t', skiprows=lambda i: i>0 and random.random() > 0.0007)\n",
    "\n",
    "kitchen_reviews = pd.read_csv(\"D:/fyp-data/amazon_reviews/amazon_reviews_us_Kitchen_v1_00.tsv\",\n",
    "                      usecols=['review_body', 'star_rating'], sep='\\t', skiprows=lambda i: i>0 and random.random() > 0.0005)\n",
    "\n",
    "automotive_reviews = pd.read_csv(\"D:/fyp-data/amazon_reviews/amazon_reviews_us_Automotive_v1_00.tsv\",\n",
    "                      usecols=['review_body', 'star_rating'], sep='\\t', skiprows=lambda i: i>0 and random.random() > 0.0008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_reviews.to_csv(\"book_reviews.csv\")\n",
    "music_reviews.to_csv(\"music_reviews.csv\")\n",
    "electronics_reviews.to_csv(\"electronics_reviews.csv\")\n",
    "kitchen_reviews.to_csv(\"kitchen_reviews.csv\")\n",
    "automotive_reviews.to_csv(\"automotive_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and save panda dataframe containing multiple review categories.\n",
    "mixed_reviews = pd.concat([book_reviews, music_reviews, electronics_reviews, kitchen_reviews, automotive_reviews])\n",
    "mixed_reviews.to_csv(\"mixed_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load reviews.\n",
    "reviews = pd.read_csv(\"mixed_reviews.csv\")\n",
    "#Drop first column with previous indexes.\n",
    "reviews = reviews.drop(reviews.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"kitchen_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert all review bodies from object to string.\n",
    "reviews[\"review_body\"] = reviews[\"review_body\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create panda column with number of capital letters in each review body.\n",
    "reviews[\"capital_letters\"] = [sum(map(str.isupper, body)) for body in reviews[\"review_body\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(frame, text):\n",
    "    frame[text] = frame[text].str.replace(r\"[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
    "    frame[text] = frame[text].str.replace(r\"http\\S+\", \"\")\n",
    "    frame[text] = frame[text].str.lower()\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = text_preprocessing(reviews, \"review_body\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenise the review body.\n",
    "tokeniser = RegexpTokenizer(r\"\\w+\")\n",
    "reviews[\"tokens\"] = reviews[\"review_body\"].apply(tokeniser.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create another column with sentence length of each review body.\n",
    "reviews[\"sentence_length\"] = [len(tokens) for tokens in reviews[\"tokens\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the sentiment score function to each review and discard those whose embeddings were not found.\n",
    "reviews[\"sentiment_score\"] = reviews[\"tokens\"].apply(get_sentiment_score)\n",
    "reviews = reviews.dropna(subset=[\"sentiment_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.groupby(\"star_rating\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = reviews[[\"sentiment_score\"]]\n",
    "labels = reviews[\"star_rating\"].tolist()\n",
    "#Splitting train/test data 80/20 known as Pareto principle, random state so that we can reproduce our results.\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling\n",
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of Words and TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = reviews[\"review_body\"].tolist()\n",
    "labels = reviews[\"star_rating\"].tolist()\n",
    "#Splitting train/test data 80/20 known as Pareto principle, random state so that we can reproduce our results.\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bow_embeddings(data):\n",
    "    vectoriser = CountVectorizer()\n",
    "\n",
    "    emb = vectoriser.fit_transform(data)\n",
    "    return emb, vectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, vectoriser = get_bow_embeddings(X_train)\n",
    "X_test = vectoriser.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(data):\n",
    "    transformer = TfidfTransformer()\n",
    "    \n",
    "    train = transformer.fit_transform(data)\n",
    "    return train, transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, vectoriser = tfidf(X_train)\n",
    "X_test = vectoriser.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_train)\n",
    "X = pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1],\n",
    "            c=y_train, edgecolor='none', alpha=0.5,\n",
    "            cmap=plt.cm.get_cmap('Spectral', 10))\n",
    "plt.xlabel('component 1')\n",
    "plt.ylabel('component 2')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 50, random_state = 42)\n",
    "model = rf.fit(X_train, y_train)\n",
    "\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "model = lr.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate abs erros\n",
    "errors = abs(predictions - y_test)\n",
    "# Mean absolute error\n",
    "mae = round(np.mean(errors), 2)\n",
    "#Mean absolute percentage error\n",
    "mape = 100 * (errors / y_test)\n",
    "accuracy = 100 - np.mean(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LogisticRegression(C=30.0, class_weight='balanced', solver='newton-cg', multi_class='multinomial',\n",
    "                         n_jobs=-1, random_state=40)\n",
    "model = regressor.fit(X_train, y_train)\n",
    "\n",
    "predictions = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-nearest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = neighbors.KNeighborsClassifier(n_neighbors = 5)\n",
    "model = classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "ax = sns.heatmap(cm, annot=True, cmap='Greens', fmt='g', linewidths=.5, cbar=False, xticklabels = ['1-star', '2-star', '3-star', '4-star', '5-star'],\n",
    "                yticklabels = ['1-star', '2-star', '3-star', '4-star', '5-star'])\n",
    "plt.title(accuracy_score(y_test, predictions))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
    "model = rf.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 50, random_state = 42)\n",
    "model = rf.fit(X_train, y_train)\n",
    "\n",
    "predictions = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate abs erros\n",
    "errors = abs(predictions - y_test)\n",
    "# Mean absolute error\n",
    "mae = round(np.mean(errors), 2)\n",
    "#Mean absolute percentage error\n",
    "mape = 100 * (errors / y_test)\n",
    "accuracy = 100 - np.mean(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "rows = []\n",
    "with open(\"D:/fyp-data/word_embeddings/glove.6B.300d.txt\", encoding='utf-8') as infile:\n",
    "    for i, line in enumerate(infile):\n",
    "        items = line.rstrip().split(' ')\n",
    "        if len(items) == 2:\n",
    "            continue\n",
    "        labels.append(items[0])\n",
    "        values = np.array([float(x) for x in items[1:]], 'f')\n",
    "        rows.append(values)\n",
    "\n",
    "arr = np.vstack(rows)\n",
    "word_embeddings = pd.DataFrame(arr, index=labels, dtype='f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_lexicon(filename):\n",
    "    lex = []\n",
    "    with open(filename, encoding='utf-8') as infile:\n",
    "        for line in infile:\n",
    "            line = line.rstrip()\n",
    "            if line and not line.startswith(';'):\n",
    "                lexicon.append(line)\n",
    "    return lexicon\n",
    "\n",
    "pos_words = load_lexicon('D:/fyp-data/sentiment_lexicons/positive-words.txt')\n",
    "neg_words = load_lexicon('D:/fyp-data/sentiment_lexicons/negative-words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_vectors = word_embeddings.reindex(pos_words).dropna()\n",
    "neg_vectors = word_embeddings.reindex(neg_words).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = pd.concat([pos_vectors, neg_vectors])\n",
    "targets = np.array([1 for entry in pos_vectors.index] + [-1 for entry in neg_vectors.index])\n",
    "labels = list(pos_vectors.index) + list(neg_vectors.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors, test_vectors, train_targets, test_targets, train_labels, test_labels = \\\n",
    "    train_test_split(vectors, targets, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDClassifier(loss='log', random_state=0, max_iter=200)\n",
    "model.fit(train_vectors, train_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(model.predict(test_vectors), test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "rf_model = rf.fit(train_vectors, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(rf_model.predict(test_vectors), test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_sentiment(words):\n",
    "    #Find embeddings for each word and discard words whose embeddings are not in the glove word embedding.\n",
    "    embedding = word_embeddings.reindex(words).dropna()\n",
    "    \n",
    "    if embedding.shape[0] == 0:\n",
    "        #Return 0 as sentiment score.\n",
    "        word_sentiment = 0\n",
    "    else:\n",
    "        log_predictions = model.predict_log_proba(embedding)\n",
    "        word_sentiment = log_predictions[:, 1] - log_predictions[:, 0]\n",
    "    \n",
    "    return pd.DataFrame({'sentiment': word_sentiment}, index=embedding.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show examples from the test set\n",
    "words_to_sentiment(test_labels).iloc[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score(text):\n",
    "    sentiment = words_to_sentiment(text)\n",
    "    #Will return empty cell when sentiment is 0(when the word embedding is not found)\n",
    "    return sentiment['sentiment'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentiment_score(['These', 'headphones', 'are', 'awful'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
